AWSTemplateFormatVersion: '2010-09-09'

Description: This template provisions a single IAM User and an IAM User Access Key
  
Metadata:
  Purpose:
    Description: "This template is used to create a stack that implements a single IAM User with an accompanying IAM Access Key.  
                  The user can be associated with an IAM Group and/or one of several Managed Policies offered by AWS.  Each managed 
                  policy maps to a traditional user job function/role. The stack exports both the user name and ARN, and outputs
                  the access key id and secret on successful deployment."

  AWS::CloudFormation::Interface:
    ParameterGroups:
      -
        Label:
          default: "IAM User Account Parameters"
        Parameters:
          - Group
          - ManagedPolicy
          - Password
          - PasswordResetRequired
          - Path
          - UserName
    ParameterLabels:
      Group:
        default: IAM Group
      ManagedPolicy:
        default: Managed Policy
      Password:
        default: User Password
      PasswordResetRequired:
        default: Password Reset required
      Path:
        default: Path
      UserName: 
        default: User Name


Parameters:

  Group:
    Type: String
    Description: Would you like to add this user to an IAM Group, or list of IAM Groups?
    ConstraintDescription: Must be a comma separated list of IAM Group names (group1,group2,group3)
    Default: "None"

  ManagedPolicy:
    Type: String
    Description: Would you like to associate a predefined Managed Policy with the user?
    AllowedValues:
    - Administrator
    - Billing
    - DatabaseAdministrator
    - DataScientist
    - DeveloperPowerUser
    - NetworkAdministrator
    - SecurityAuditor
    - SupportUser
    - SystemAdministrator
    - View-Only
    - None
    Default: None

  Password:
    Type: String
    Description: Please enter a password 
    ConstraintDescription: Password must be between 8 and 32 characters, start with lowercase or uppercase letter, and can be alphanumeric with the following special characters !@#$%& 
    NoEcho: true
    AllowedPattern: ^[a-zA-Z][a-zA-Z0-9!@#$%&]{8,32}$

  PasswordResetRequired:
    Type: String
    Description: Do you want to require users to create a new password on first login?
    ConstraintDescription: Must be a boolean value of true or false
    Default: "false"
    AllowedValues: 
    - "true"
    - "false"

  Path:
    Type: String
    Description: What IAM Path would you like to associate with the User?
    AllowedPattern: (^\/$)|(^\/.*\/$)
    Default: "/"

  UserName:
    Type: String
    Description: Would you like to define a UserName for the IAM User?
    AllowedPattern: ^[\w+=,.@-]{1,64}$
    ConstraintDescription: This parameter allows a string of characters consisting of upper and lowercase alphanumeric characters with no spaces, and the following special characters [\w+=,.@-]+
    Default: "None"

  SESFromEmail:
    Description: Email to be used for sending the AWS SES notification once the IAM user is created
    Type: String
    AllowedPattern: '[^@]+@[^@]+\.[^@]+'
    Default: "bedwinlab@gmail.com"

Mappings:

  ManagedPolicies:
    Administrator: 
      ARN: arn:aws:iam::aws:policy/AdministratorAccess
      GroupRole: AdministratorAccess
    Billing: 
      ARN: arn:aws:iam::aws:policy/job-function/Billing
      GroupRole: Billing
    DatabaseAdministrator: 
      ARN: arn:aws:iam::aws:policy/job-function/DatabaseAdministrator
      GroupRole: DatabaseAdministrator
    DataScientist: 
      ARN: arn:aws:iam::aws:policy/job-function/DataScientist
      GroupRole: DataScientist
    DeveloperPowerUser: 
      ARN: arn:aws:iam::aws:policy/PowerUserAccess
      GroupRole: PowerUserAccess
    NetworkAdministrator: 
      ARN: arn:aws:iam::aws:policy/job-function/NetworkAdministrator
      GroupRole: NetworkAdministrator
    SecurityAuditor: 
      ARN: arn:aws:iam::aws:policy/SecurityAudit
      GroupRole: SecurityAudit
    SupportUser: 
      ARN: arn:aws:iam::aws:policy/job-function/SupportUser
      GroupRole: SupportUser
    SystemAdministrator: 
      ARN: arn:aws:iam::aws:policy/job-function/SystemAdministrator
      GroupRole: SystemAdministrator
    View-Only: 
      ARN: arn:aws:iam::aws:policy/job-function/ViewOnlyAccess
      GroupRole: ViewOnlyAccess
    None: 
      ARN: arn:aws:iam::aws:policy/NoAccess
      GroupRole: NoAccess


Conditions:

  hasManagedPolicy:
    !Not [!Equals [!Ref ManagedPolicy, "None"]]

  hasUserName: 
    !Not [!Equals [!Ref UserName, "None"]]

  hasGroup:
    !Not [!Equals [!Ref Group, "None"]]


Resources:

  User:
    Type: AWS::IAM::User
    Properties:
      Groups: 
        - !If [hasGroup, !Ref Group, !Ref "AWS::NoValue"]
      LoginProfile:
        Password: !Ref Password
        PasswordResetRequired: !Ref PasswordResetRequired
      ManagedPolicyArns:
        - !If [hasManagedPolicy, !FindInMap [ManagedPolicies, !Ref ManagedPolicy, ARN], !Ref "AWS::NoValue"]
      Path: !Ref Path
      UserName: !If [hasUserName, !Ref UserName, !Ref "AWS::NoValue"]

  AccessKey:
    Type: AWS::IAM::AccessKey
    Properties: 
      UserName: !Ref User

  SESConfigSet:
    Type: 'AWS::SES::ConfigurationSet'
    Properties:
      Name: CustomConfigSet

  S3GithubTemplatesName:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Join
        - "-"
        - - "cfn-datascientest-sandbox-templates-repo"
          - !Select
            - 0
            - !Split
              - "-"
              - !Select
                - 2
                - !Split
                  - "/"
                  - !Ref "AWS::StackId"

  
  LambdaFunctionUserNotification:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: caller
      Handler: index.lambda_handler
      Role: !GetAtt 'LambdaRole.Arn'
      Environment:
        Variables:
          SES_FROM_EMAIL:
            Ref: SESFromEmail
          SES_CONFIG_SET_NAME:
            Ref: SESConfigSet
          SES_User_NAME:
            Ref: User
          SES_User_Password:
            Ref: Password
          SES_User_AccessKey:
            Ref: AccessKey
          SES_User_SecretKey: !GetAtt AccessKey.SecretAccessKey
      Runtime: python3.9
      Timeout: 60
      Code:
        ZipFile: |
              import os
              import boto3
              import json
              from datetime import datetime

              from_email = os.environ["SES_FROM_EMAIL"]
              config_set_name = os.environ["SES_CONFIG_SET_NAME"]
              user_name = os.environ["SES_User_NAME"]
              user_pass = os.environ["SES_User_Password"]
              user_access_key = os.environ["SES_User_AccessKey"]
              user_secret_key = os.environ["SES_User_SecretKey"]

              client = boto3.client('ses')

              def lambda_handler(event, context):

                  body_html = f"""<html>
                      <head></head>
                      <body>
                        <h2>CYour Datascientest AWS Sandbox is live!</h2>
                        <br/>
                        <p>You have been granted access to an aws sandbox environment.
                        You could login to AWS using the following account id: </p> 
                        <p> For console access, use the following credentials: {bedwinlab@gmail.com} </p>
                          - username: {user_name}
                          - password: {user_pass}
                        <p>For programatic access, use the following access key and secret key within your aws cli:</p>
                          - AccessKey: {user_access_key}
                          - SecretKey: {user_secret_key}
                        </body>
                      </html>
                                  """

                  email_message = {
                      'Body': {
                          'Html': {
                              'Charset': 'utf-8',
                              'Data': body_html,
                          },
                      },
                      'Subject': {
                          'Charset': 'utf-8',
                          'Data': "Your Datascientest AWS Sandbox is ready",
                      },
                  }

                  ses_response = client.send_email(
                      Destination={
                          'ToAddresses': ['bedwinlab@gmail.com'],
                      },
                      Message=email_message,
                      Source=from_email,
                      ConfigurationSetName=config_set_name,
                  )
                  # print(f"ses response id received: {response['MessageId']}.")

 # Primerinvoke:
 #   Type: AWS::CloudFormation::CustomResource
 #   DependsOn: LambdaFunctionUserNotification
 #   Version: "1.0"
 #   Properties:
 #     ServiceToken: !GetAtt LambdaFunctionUserNotification.Arn

  LambdaRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: DatascientestUSerCreationRole
      Description: An execution role for a Lambda function launched by CloudFormation
      ManagedPolicyArns:
        - !Ref LambdaPolicy
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service: lambda.amazonaws.com
          Action:
          - 'sts:AssumeRole'
        
  LambdaPolicy:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      ManagedPolicyName: DatascientestUSerCreationPolicy
      Description: Managed policy for a Lambda function launched by CloudFormation
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Action:
              - 'ses:*'
              - 's3:*'
            Resource: '*'
          - Effect: Allow
            Action:
              - 'logs:CreateLogGroup'
              - 'logs:CreateLogStream'
              - 'logs:PutLogEvents'
            Resource: '*'
                  
  # Define the consumer Lambda function for filling S3 sandbox and invoking the user lambda defined above 
  SandboxInitConsumerFunction:
    Type: 'AWS::Lambda::Function'
    Properties:
      FunctionName: sandboxTrigger
      Handler: index.lambda_handler
      Role: !GetAtt 'LambdaRole.Arn'
      MemorySize: 2048
      Runtime: python3.9
      Timeout: 60
      Environment:
        Variables:
          S3_GITHUB_TEMPLATES_NAME:
            Ref: S3GithubTemplatesName
      Code:
        ZipFile: |
                import os
                import boto3
                import json
                import urllib.request
                from zipfile import ZipFile
                import tempfile

                s3 = boto3.client('s3')

                def lambda_handler(event, context):
                  bucket_name = os.environ["S3_GITHUB_TEMPLATES_NAME"]
                  print("Download first layer files")
                  temppath = tempfile.gettempdir()

                  upload_2_s3('https://raw.githubusercontent.com/datascientest-aws/sandbox-automation/main/custom-layer/index.sh', "index.sh")
                  upload_2_s3('https://raw.githubusercontent.com/datascientest-aws/sandbox-automation/main/custom-layer/bootstrap', "bootstrap")
                  upload_2_s3('https://raw.githubusercontent.com/datascientest-aws/sandbox-automation/main/custom-layer/README.md', "README.md")

                  # update lambda name in index.sh using the new variable
                  with ZipFile(temppath+'/'+'custom.zip','w') as zip:
                  # writing each file one by one
                    zip.write(temppath+'/index.sh')
                    zip.write(temppath+'/README.md')
                    zip.write(temppath+'/bootstrap')
                    
                  s3.put_object(Bucket=bucket_name, Key="custom.zip", StorageClass='REDUCED_REDUNDANCY', Body=open(temppath+'/custom.zip', 'rb'))
                  #upload_2_s3('https://github.com/datascientest-aws/sandbox-automation/raw/main/custom-layer/custom.zip', "custom.zip")

                  print("Download second layer files")
                  upload_2_s3('https://raw.githubusercontent.com/datascientest-aws/sandbox-automation/main/nuke-layer/README.md', "README.md")
                  upload_2_s3('https://raw.githubusercontent.com/datascientest-aws/sandbox-automation/main/nuke-layer/index.sh', "index.sh")
                  upload_2_s3('https://raw.githubusercontent.com/datascientest-aws/sandbox-automation/main/nuke-layer/bootstrap', "bootstrap")

                  # update lambda name in index.sh using the new variable
                  with ZipFile(temppath+'/'+'nuke.zip','w') as zip:
                  # writing each file one by one
                    zip.write(temppath+'/index.sh')
                    zip.write(temppath+'/README.md')
                    zip.write(temppath+'/bootstrap')
                  #upload_2_s3('https://github.com/datascientest-aws/sandbox-automation/blob/main/nuke-layer/nuke.zip', "nuke.zip")
                  s3.put_object(Bucket=bucket_name, Key="nuke.zip", StorageClass='REDUCED_REDUNDANCY', Body=open(temppath+'/nuke.zip', 'rb'))

                  upload_2_s3('https://raw.githubusercontent.com/datascientest-aws/sandbox-automation/main/aws-alerting-service.yaml', "aws-alerting-service.yaml")  
                  upload_2_s3('https://raw.githubusercontent.com/datascientest-aws/sandbox-automation/main/aws-billing-alert.yml', "aws-billing-alert.yml")  
                  upload_2_s3('https://raw.githubusercontent.com/datascientest-aws/sandbox-automation/main/aws-freeze-service.yaml', "aws-freeze-service.yaml")  
                  upload_2_s3('https://raw.githubusercontent.com/datascientest-aws/sandbox-automation/main/aws-wipe-service.yaml', "aws-wipe-service.yaml")  
                  upload_2_s3('https://raw.githubusercontent.com/datascientest-aws/sandbox-automation/main/aws-user-service.yaml',"aws-user-service.yaml")

                def update_S3_name(filename):
                  temppath = tempfile.gettempdir()
                  bucket_name = os.environ["S3_GITHUB_TEMPLATES_NAME"]+'.s3.amazonaws.com'
                  fin = open(temppath+"/"+filename, "rt")
                  data = fin.read()
                  data = data.replace('cf-template-datascientest-sandboxes.s3.amazonaws.com', bucket_name)
                  fin.close()
                  fin = open(temppath+"/"+filename, "wt")
                  fin.write(data)
                  fin.close()

                def upload_2_s3(file_url, name):
                    bucket_name = os.environ["S3_GITHUB_TEMPLATES_NAME"]
                    # Download and Create file in temp path
                    temppath = tempfile.gettempdir()
                    urllib.request.urlretrieve(file_url, temppath+'/'+name)
                    if name == 'index.sh':
                      update_S3_name(name)
                    print("# - Process AWS S3 upload")
                    s3.put_object(Bucket=bucket_name, Key=name,
                                  StorageClass='REDUCED_REDUNDANCY',
                                  Body=open(temppath+'/'+name, 'rb'))

Outputs:

  UserName: 
    Description: The UserName associated with the IAM User account
    Value: !Ref User
    Export:
      Name: !Join ["-", [!Ref "AWS::StackName", "user-name"]]

  UserARN:
    Description: The ARN associated with the IAM User account
    Value: !GetAtt User.Arn
    Export:
      Name: !Join ["-", [!Ref "AWS::StackName", "user-arn"]]
    
  AccessKeyId:
    Description: the Access Key Id 
    Value: !Ref AccessKey
    
  AccessKeySecret:
    Description: the Access Key Secret
    Value: !GetAtt AccessKey.SecretAccessKey